<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>S15: 15-618 Final Project by hpandit and rbandlam</title>
    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/pygment_trac.css">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.7.1/jquery.min.js"></script>
    <script src="javascripts/respond.js"></script>
    <!--[if lt IE 9]>
      <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    <!--[if lt IE 8]>
    <link rel="stylesheet" href="stylesheets/ie.css">
    <![endif]-->
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <style>
    table, th, td {
        border: 1px solid white;
        border-collapse: collapse;
    }
    th, td {
        padding: 2px;
    }
    th,td  {
    text-align: center;
    } 
    body {
    background-color: DarkSlateBlue ;
    }
    pre { 
    background-color: white;
    }
    img.resize{
    max-width:40%;
    max-height:40%;
    }
  </style>
  </head>
  <body>
    <div class="wrapper">
      <section>
        <div id="title" >
          <h1 style="color:DarkTurquoise">"CUDA Factor": A Library of Matrix Factorization routines  </h1>
          <p> Harshavardhan Pandit and Ravi Chandra Bandlamudi</p>
          <br>
          <br>
          <hr>
          <br>
          <br>
          <br>
          <br>
          <h2 style="color:DarkTurquoise">
          <a id="Index" class="bottom-three" href="#Index" aria-hidden="true"><span class="octicon octicon-link">
            </span></a><center><bottom-three><a href="#Writeup" style="color:DarkTurquoise; text-decoration:underline;">Writeup</a> &nbsp; :: &nbsp;
              <a href="#Checkpoint" style="color:DarkTurquoise; text-decoration:underline">Checkpoint</a> &nbsp; :: &nbsp; 
              <a href="#Proposal" style="text-decoration:underline; color:DarkTurquoise">Proposal</a></bottom-three></center></h2>
          <br>
          <br>
          <h2><center>
          <a href="#Competition" style="text-decoration:underline; color:Plum">Spring 2015 Parallelism Competition</a></bottom-three></center></h2>
          <br>
          <br>
          <br>
          <br>    
        </div>

<h1 style="color:Plum">
<a id="Competition" class="anchor" href="#Competition" aria-hidden="true"><span class="octicon octicon-link"></span></a><center>Spring 2015 Parallelism Competition</center></h2>

<p>Welcome to our project page for the Spring 2015 Parallelism Competition! This section provides a brief description of our project goals, deliverables and preliminary results. For a more detailed description, please visit the <a href="#Writeup" style="color:DarkTurquoise">writeup</a> section.</p>

<h2 style="color:white">
<a id="SummaryComp" class="anchor" href="#SummaryComp" aria-hidden="true"><span class="octicon octicon-link"></span></a>Summary</h2>
<p>  We have developed a library of GPU-accelerated optimized matrix factorization routines in CUDA. The routines
    currently implemented are:
    <ul>
    <li><a href="#LU Factorization1" style="color:DarkTurquoise">LU Factorization</a> <i><b> ( A = LU )</i></b></li> 
    <li><a href="#QR Factorization1" style="color:DarkTurquoise">QR Factorization</a> <i><b> ( A = QR )</i></b></li> 
    <li><a href="#Cholesky Factorization1" style="color:DarkTurquoise">Cholesky Factorization</a> <i><b> ( A = LL<sup>T</sup> )</i></b></li> 
    </ul>
    We have also designed an <a href="#R interface" style="color:DarkTurquoise">R interface</a> to use 
    the routines in this library in <a href="http://www.r-project.org/" style="color:DarkTurquoise">R</a>.</p>

<h2 style="color:white">
<a id="ResultsComp" class="anchor" href="#ResultsComp" aria-hidden="true"><span class="octicon octicon-link"></span></a>Results</h2>

<p>At the competition, we would be showing a comparison of our library routines to the state-of-the-art libraries such as <a href="http://docs.nvidia.com/cuda/cublas/index.html#axzz3ZR8Xl4Om" style="color:DarkTurquoise">cuBLAS</a> and <a href="http://www.culatools.com/" style="color:DarkTurquoise">CULA</a>. Some preliminary results are shown below. Owing to better algorithms and their efficient implementation, we are able to beat the reference libraries by a huge margin, especially for higher matrix sizes. </p>

<p>The following graph shows a comparison between our LU implementation and the <a href="http://docs.nvidia.com/cuda/cublas/index.html#axzz3ZR8Xl4Om" style="color:DarkTurquoise">cuBLAS reference</a> when run on a <a href="http://www.geforce.com/hardware/desktop-gpus/geforce-gtx-670" style="color:DarkTurquoise">GTX 670 GPU</a>. </p>

<center><img class="resize" src="images/LU_results.png" alt="LU results graph" align="middle"></center> 
 <p><center>Performance of Our LU Routine</center></p>

 <p>The following graph shows a comparison between our QR implementation and the <a href="http://docs.nvidia.com/cuda/cublas/index.html#axzz3ZR8Xl4Om" style="color:DarkTurquoise">cuBLAS reference</a> when run on a <a href="http://www.nvidia.com/object/tesla-servers.html" style="color:DarkTurquoise">Tesla K40</a>. The <a href="http://docs.nvidia.com/cuda/cublas/#cublas-lt-t-gt-geqrfbatched" style="color:DarkTurquoise">cuBLAS QR routine</a> is intended to be used for performing QR factorization on many small matrices in parallel, we have however focused on computing the factorization for one huge matrix as fast as possible. Such an use case is important as well, for instance, during PCA (Principal Component Analysis) calculations in Machine Learning algorithms.</p>

<center><img class="resize" src="images/QR_results1.png" alt="QR results Tesla graph" align="middle"></center> 
 <p><center>Performance of Our QR Routine on <a href="http://www.nvidia.com/object/tesla-servers.html" style="color:DarkTurquoise">Tesla K40</a></center></p>

  <p>The following graph shows a comparison between our QR implementation and the <a href="http://docs.nvidia.com/cuda/cublas/index.html#axzz3ZR8Xl4Om" style="color:DarkTurquoise">cuBLAS reference</a> when run on a <a href="http://www.geforce.com/hardware/desktop-gpus/geforce-gtx-670" style="color:DarkTurquoise">GTX 670 GPU</a>. </p>

<center><img class="resize" src="images/QR_results_670.png" alt="QR results 670 graph" align="middle"></center> 
 <p><center>Performance of our QR Routine on <a href="http://www.geforce.com/hardware/desktop-gpus/geforce-gtx-670" style="color:DarkTurquoise">GTX 670</a></center></p>

<br><br>

<h1 style="color:Aqua">
<a id="Writeup" class="anchor" href="#Writeup" aria-hidden="true"><span class="octicon octicon-link"></span></a><center>Writeup</center></h2>

<h2 style="color:white">
<a id="Summary" class="anchor" href="#Summary1" aria-hidden="true"><span class="octicon octicon-link"></span></a>Summary</h2>
<p>  We have developed a library of GPU-accelerated optimized matrix factorization routines in CUDA. The routines
    currently implemented are:
    <ul>
    <li><a href="#LU Factorization1" style="color:DarkTurquoise">LU Factorization</a> <i><b> ( A = LU )</i></b></li> 
    <li><a href="#QR Factorization1" style="color:DarkTurquoise">QR Factorization</a> <i><b> ( A = QR )</i></b></li> 
    <li><a href="#Cholesky Factorization1" style="color:DarkTurquoise">Cholesky Factorization</a> <i><b> ( A = LL<sup>T</sup> )</i></b></li> 
    </ul>
    We have also designed an <a href="#R interface" style="color:DarkTurquoise">R interface</a> to use 
    the routines in this library in <a href="http://www.r-project.org/" style="color:DarkTurquoise">R</a>.</p>
    
<h2 style="color:white">
<a id="Background" class="anchor" href="#Background1" aria-hidden="true"><span class="octicon octicon-link"></span></a>Background</h2>

<p> Matrix factorizations/decompositions are computationally intensive linear algebra operations that are commonly
used in problems like matrix inversion, solving linear systems etc. These factorizations therefore find application
in numerous fields - any place where you would solve a system of linear equations! <br>
Domain-specific languages such as R and MATLAB have in-built functions for many matrix decompositions which are easy
to use, but are understandably very slow especially on large matrices. The aim of this project is to design a
library wherein 3 factorizations - LU, QR and Cholesky - would be implemented in CUDA and an interface to these
functions would be provided in R. Algorithms written in R which use these factorizations can benefit hugely in
terms of speedup from using this library. GPU-accelerated routines for these factorizations exist in libraries 
such as <a href="http://docs.nvidia.com/cuda/cublas/index.html#axzz3ZR8Xl4Om" style="color:DarkTurquoise">cuBLAS</a>, <a href="http://www.culatools.com/" style="color:DarkTurquoise">CULA</a> [1] etc. which serve as reference implementations for our library.</p>

<h4 style="color:white">
<a id="LU Factorization2" class="anchor" href="#LU2" aria-hidden="true"><span class="octicon octicon-link"></span></a>LU Factorization</h4>

<p>  A non-singular matrix <i><b>A &isin; &real;<sup><i><b>n x n</b></i></sup></b></i> is factorized into a product of
lower and upper triangular matrices <i><b>L &isin; &real;<sup>n x n</sup></b></i> and <i><b>U &isin; &real;<sup>n x n</sup></b></i>
respectively such that <i><b>A = LU</i></b> </p>

<p> A sequential "right-looking" algorithm loops over columns and updates columns to its right based on
    the current column [2]. The following pseudo-code describes the algorithm: </p>
    
 <code><pre>
 <font color="black">
    for i=1 to N  /*loop over columns*/
      for j= i+1 to N
        A(j,i) = A(j,i)/A(i,i)  /*update L*/
        for k=i+1 to N  
          A(j,k) = A(j,k) - A(i,k)*A(j,i)  /*update U*/
        end
      end
    end  
  </font></pre>
 </code>  
 <!-- <center>LU factorization - Pseudo code</center> -->

The algorithm therefore prescribes that the data dependency flows from left to right - in other words, the matrix 
columns to the right depend on the columns to the left. Updating <i><b>U</i></b> is the most computation intensive
part of this algorithm and hence all efforts are focused on extracting parallelism in this update. Operating over
rows and columns of a matrix hints that there is data locality to be exploited in these memory accesses. 
<br><br>

<h4 style="color:white">
<a id="QR Factorization2" class="anchor" href="#QR2" aria-hidden="true"><span class="octicon octicon-link"></span></a>QR Factorization</h4>

<p>  A rectangular matrix <i><b>A &isin; &real;<sup><i><b>m x n</b></i></sup></b></i> is factorized into a product of
orthogonal and upper triangular matrices <i><b>Q &isin; &real;<sup>m x m</sup></b></i> and <i><b>R &isin; &real;
<sup>m x n</sup></b></i> respectively such that <i><b>A = QR</i></b> </p>

<p>One of the ways of computing the QR Factorization involves a method of applying orthogonal transformations
  known as "Householder reflections" [3]. Without delving  into the details of the algorithm, the 
  following pseudo-code attempts at describing the various major parts in the algorithm and their characteristics:</p>

<code><pre>
 <font color="black">
    // Input: Matrix A
    for each block  /*loop over columns in blocks*/
      for j = 1 to blocksize
        // Find Householder vector
        // Update A
      end
      
      // Initialize helper matrices Y & W
      
      for j = 2 to blocksize
        // Update Y
        // Update W
      end
      
      // Update A  
    end  
  </font></pre>
 </code>
 <!--  <center>QR factorization - Pseudo code</center> -->
 
 <p>Within the scope of this project, the only important things to know about the above pseudo-code are - one,
  finding the householder vector involves <b>calculating norms</b> of vectors and two, the update A, Y & W parts
  consist of one or more <b>matrix-matrix multiplications</b>. As the size of the input matrix increases,
  these matrix products start becoming more and more computationally intensive. Therefore, unlike in the case of the LU
  factorization where data locality played an important role, here the emphasis is on matrix-matrix multiplications.
  Also worth noting is that within each of the for loop denoted in the pseudo-code, the iterations are not
  independent since the "Update" phases depend on the outputs of the previous iteration.</p>
  
<h4 style="color:white">
<a id="Cholesky Factorization2" class="anchor" href="#Chol2" aria-hidden="true"><span class="octicon octicon-link"></span></a>Cholesky Factorization</h4>

<p>  A symmetric (<b><i>A = A<sup>T</sup></i></b>) and positive definite (<i><b>x<sup>T</sup>Ax > 0</b></i> for all
<i><b>x &isin; &real; <sup>n</sup>, x &ne; 0 </b></i>) matrix <i><b>A &isin; &real;<sup><i><b>n x n</b></i></sup>
</b></i> is factorized into a product of a lower triangular matrix <i><b>L &isin; &real;<sup>n x n</sup></b></i> 
and its transpose such that <i><b>A = LL<sup>T</sup></i></b> </p>

<p>Similar to the LU factorization algorithm, the sequential algorithm of the Cholesky factorization [4] has a dependency flow from left to right. In other words, the matrix columns to the right depend on the columns to the left. </p>

 <code><pre>
 <font color="black">
    for k=1 to N  /*loop over columns*/
      A(k,k) = &radic;A(k,k)
      for i = k+1 to N
        A(i,k) = A(i,k)/A(k,k)  /*update current column*/
      end

      for j=k+1 to N  
        for i=j to N 
          A(i,j) = A(i,j) - A(i,k)*A(j,k)  /*update sub-matrix*/
        end
      end
    end  
  </font></pre>
 </code> 
<!--  <center>Cholesky factorization - Pseudo code [4]</center> -->

<p>Updating the sub-matrix is the most computation intensive part of this algorithm and hence all efforts are focused on extracting parallelism in this update. Operating over rows and columns of a matrix hints that there is data locality to be exploited in these memory accesses.</p>

<h2 style="color:white">
<a id="Approach" class="anchor" href="#Approach" aria-hidden="true"><span class="octicon octicon-link"></span></a>Approach</h2>

<h4 style="color:white">
<a id="LU Factorization3" class="anchor" href="#LU3" aria-hidden="true"><span class="octicon octicon-link"></span></a>LU Factorization</h4>

<p> We implemented a parallel version of the LU factorization algorithm on the <a 
    href="http://www.geforce.com/hardware/desktop-gpus/geforce-gtx-670" style="color:DarkTurquoise">GTX 670 
    GPU</a> in the GHC machines. To begin with, the sequential algorithm was implemented using the pseudo-code in [2].
    The sequential algorithm was slightly modified to enable better mapping to a GPU
    - this was done by separating the loops which involve updating the L and the U parts of the matrix. </p>
    
<center><img class="resize" src="images/LU.png" alt="Mapping for LU factorization" align="middle"></center> 
 <p><center>LU - Matrix update at i<sup>th</sup> iteration</center></p>
 
 <p>The figure above shows the part of the matrix that is updated at the i<sup>th</sup> iteration. To begin with,
 the most simple approach was implemented wherein each element of this sub-matrix is assigned a thread and a kernel
 with required number of blocks and threads per block is launched. To experiment with different memory access patterns,
 two other mappings were tried out. First, the sub-matrix is divided into blocks as before, but within the block
 only one thread per row of the block is launched (instead of one thread per element). Second, the same thing is
 done with columns - one thread per column of the block is launched. These two approaches characterize different 
 memory access patterns but both have one common advantage - enabling use of shared memory. In the figure above, the 
 row and the column shaded grey is shared by all the elements in the sub-matrix to perform their update.
 Hence, in a per-row or a per-column method, the part of the row and the column shared is first loaded into shared memory
 which is then used by all the threads within the thread block to perform their update.</p>
 
<h4 style="color:white">
<a id="QR Factorization3" class="anchor" href="#QR3" aria-hidden="true"><span class="octicon octicon-link"></span></a>QR Factorization</h4>

<p>A parallel version of the QR factorization algorithm was implemented on the <a href="http://www.nvidia.com/object/tesla-servers.html" 
style="color:DarkTurquoise">Tesla K40</a> in the latedays cluster as well as on the <a href="http://www.geforce.com/hardware/desktop-gpus/geforce-gtx-670" style="color:DarkTurquoise">GTX 670 GPU</a> in the GHC machines. To begin with, the sequential algorithm was implemented using the pseudo-code in [3].</p>

<p>As a first simple approach, we started by implementing a naive CUDA version of the Householder QR factorization. QR was much more challenging than the LU factorization especially since the sizes of the matrices involved in the "Update" phases (refer to pseudo-code above) vary every iteration. Hence, dynamic memory allocations within the for loop were abundant in the first implementation. Also, to keep things simple the householder function (which involves calculating norms) was implemented on the host side instead of the GPU. This meant a memory transfer over the bus every iteration.</p>

<p>Several iterations of optimizations followed this basic CUDA implementation since it wasn't close to the reference cuBLAS library implementation. The first thing which we felt could have been the bottle neck was the expensive memory transfer over the PCI-e bus every iteration. To get rid of this, the implementation of Householder function was moved to the GPU instead of the host CPU. This was done by storing the squares of the input vector (recall that the l<sub>2</sub> norm is the square root of the sum of the squares of the elements in a vector) in an array and performing an <a href="http://15418.courses.cs.cmu.edu/spring2015/lecture/exclusivescan" style="color:DarkTurquoise">exclusive scan</a> on this array.</p>

<p>Another possible cause of the inefficiency could have been the dynamic allocation of the arrays within the loops. This overhead of allocating and freeing memory every iteration due to variable sizes could have been affecting performance was our intuition. One way to circumvent this was by taking a usual memory space v/s time trade-off. We cut down on the time spent in allocating/de-allocating memory every iteration by allocating the maximum amount of memory our code would need before the first iteration itself. The indexing within all the kernels in the loop need to be modified accordingly. This approach too did not yield desirable results and had the added drawback that due to excessive memory allocations, this implementation would break at higher matrix sizes since the device ran out of memory.</p>

<p>On profiling the code function-by-function, we found that the matrix-matrix multiplications - the backbone of the QR factorization routine - were the bottleneck restricting performance. Our matrix multiply kernel thus far was a naive one wherein each output element was calculated by a thread looping through the rows and columns of the input matrices. We then shifted our focus on improving our matrix multiply kernel.</p>

<center><img class="resize" src="images/matmult.png" alt="Matrix multiplication" align="middle"></center> 
 <p><center>Optimized matrix multiplication</center></p>

<p>The figure above shows our approach towards optimizing matrix-matrix multiplications. Like before, one thread is launched per output matrix element. However, the kernel is now modified to make efficient use of per-block shared memory. Instead of looping through one row of A and one column of B at a time, the modified kernel follows a blocked method as shown. The blocks shown in red are first loaded into shared memory - one thread loads one element into each shared sub-matrix. We now loop through the row of the red block in A and the column of the red block in B. We do the same for the blue and the green blocks to get the output element. This approach of splitting the loop iterations into blocks makes efficient use of per-block shared memory.</p>

<h4 style="color:white">
<a id="Cholesky Factorization3" class="anchor" href="#Chol3" aria-hidden="true"><span class="octicon octicon-link"></span></a>Cholesky Factorization</h4>

<h2 style="color:white">
<a id="Results" class="anchor" href="#Results" aria-hidden="true"><span class="octicon octicon-link"></span></a>Results</h2>

<h4 style="color:white">
<a id="LU Factorization1" class="anchor" href="#LU1" aria-hidden="true"><span class="octicon octicon-link"></span></a>LU Factorization</h4>

<p>The performance of our LU routine was evaluated by measuring the wall-clock time of this code and comparing it to that of the reference library. Since the <a href="http://docs.nvidia.com/cuda/cublas/index.html#axzz3ZR8Xl4Om" style="color:DarkTurquoise">cuBLAS library</a> is in-built within newer versions of CUDA (6.0 onwards), it was the first choice of a reference implementation. </p>

<p>The following graph shows a comparison between our implementation and the <a href="http://docs.nvidia.com/cuda/cublas/index.html#axzz3ZR8Xl4Om" style="color:DarkTurquoise">cuBLAS reference</a> when run on a <a href="http://www.geforce.com/hardware/desktop-gpus/geforce-gtx-670" style="color:DarkTurquoise">GTX 670 GPU</a>. </p>

<center><img class="resize" src="images/LU_results.png" alt="LU results graph" align="middle"></center> 
 <p><center>Performance of Our LU Routine</center></p>


<h4 style="color:white">
<a id="QR Factorization1" class="anchor" href="#QR1" aria-hidden="true"><span class="octicon octicon-link"></span></a>QR Factorization</h4>

<p>The performance of our QR routine was evaluated by measuring the wall-clock time of this code and comparing it to that of the reference library. Since the <a href="http://docs.nvidia.com/cuda/cublas/index.html#axzz3ZR8Xl4Om" style="color:DarkTurquoise">cuBLAS library</a> is in-built within newer versions of CUDA (6.0 onwards), it was the first choice of a reference implementation. </p>

<p>The following graph shows a comparison between our implementation and the <a href="http://docs.nvidia.com/cuda/cublas/index.html#axzz3ZR8Xl4Om" style="color:DarkTurquoise">cuBLAS reference</a> when run on a <a href="http://www.nvidia.com/object/tesla-servers.html" style="color:DarkTurquoise">Tesla K40</a>. </p>

<center><img class="resize" src="images/QR_results1.png" alt="QR results Tesla graph" align="middle"></center> 
 <p><center>Performance of Our QR Routine on <a href="http://www.nvidia.com/object/tesla-servers.html" style="color:DarkTurquoise">Tesla K40</a></center></p>

 <p>The following graph shows a comparison between our implementation and the <a href="http://docs.nvidia.com/cuda/cublas/index.html#axzz3ZR8Xl4Om" style="color:DarkTurquoise">cuBLAS reference</a> when run on a <a href="http://www.geforce.com/hardware/desktop-gpus/geforce-gtx-670" style="color:DarkTurquoise">GTX 670 GPU</a>. </p>

<center><img class="resize" src="images/QR_results_670.png" alt="QR results 670 graph" align="middle"></center> 
 <p><center>Performance of our QR Routine on <a href="http://www.geforce.com/hardware/desktop-gpus/geforce-gtx-670" style="color:DarkTurquoise">GTX 670</a></center></p>

<h4 style="color:white">
<a id="Cholesky Factorization1" class="anchor" href="#Chol" aria-hidden="true"><span class="octicon octicon-link"></span></a>Cholesky Factorization</h4>


<p>The performance of our Cholesky routine was evaluated by measuring the wall-clock time of this code and comparing it to that of the reference library. Since the <a href="http://docs.nvidia.com/cuda/cublas/index.html#axzz3ZR8Xl4Om" style="color:DarkTurquoise">cuBLAS library</a> does not have a cholesky factorization routine, we switched to a different reference - the <a href="http://www.culatools.com/" style="color:DarkTurquoise">CULA tools</a> library. </p>


<h4 style="color:white">
<a id="R interface" class="anchor" href="#R interface" aria-hidden="true"><span class="octicon octicon-link"></span></a>R Interface</h4>

<!-- -->
<p>One of the "nice to haves" of our project was designing a R interface for our library in order to enable the calling of our optimized routines from within R. For this purpose, a R wrapper was written around the CUDA QR routine and a test was created to compare the performance of the <a href="https://stat.ethz.ch/R-manual/R-devel/library/base/html/qr.html" style="color:DarkTurquoise">in-built qr() function</a> in R and the optimized QR routine from our "CUDA Factor" library. These tests were carried out on the  <a href="http://www.geforce.com/hardware/desktop-gpus/geforce-gtx-670" style="color:DarkTurquoise">GTX 670 GPU</a> in the GHC machines, which have R installed on them. </p> 

<center><img class="resize" src="images/R_vs_Ours.png" alt="R interface graph" align="middle"></center> 
 <p><center>Performance of our QR Routine against the R <a href="https://stat.ethz.ch/R-manual/R-devel/library/base/html/qr.html" style="color:DarkTurquoise">in-built qr() function</a></center></p>

<p>The figure above shows a significant speedup achieved with respect to the in-built R function by using our library.</p>

<h2>
<a id="References" class="anchor" href="#References" aria-hidden="true"><span class="octicon octicon-link"></span></a>References</h2>

 <ol type="1">
   <li>GPU-accelerated libraries,  <a href="https://developer.nvidia.com/gpu-accelerated-libraries" style="color:DarkTurquoise">https://developer.nvidia.com/gpu-accelerated-libraries</a></li>
  <li> Bandara, H. M. D. M., and D. N. Ranasinghe. <a href="http://www.hipc.org/hipc2011/studsym-papers/1569512927.pdf" style="color:DarkTurquoise">"Effective GPU Strategies for LU Decomposition"</a>. Technical report, University of Colombo, Colombo, Sri Lanka, 2010.</li>
  <li>Kerr, Andrew, Dan Campbell, and Mark Richards. <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.514.7063&rep=rep1&type=pdf"
  style="color:DarkTurquoise">"QR decomposition on GPUs."</a> 
  Proceedings of 2nd Workshop on General Purpose Processing on Graphics Processing Units. ACM, 2009.</li>
  <li><a href="https://courses.engr.illinois.edu/cs554/fa2013/notes/07_cholesky.pdf" style="color:DarkTurquoise">Parallel Numerical Algorithms</a>, Prof. Michael T. Health, University of Illinois-Urbana Champaign </li>
</ol>

<h2 style="color:white">
<a id="Work Done" class="anchor" href="#Work Done" aria-hidden="true"><span class="octicon octicon-link"></span></a>Work Done</h2>

<p> Equal work was done by both members. </p>
<h1 style="color:Aqua">
<a id="Checkpoint" class="anchor" href="#Checkpoint" aria-hidden="true"><span class="octicon octicon-link"></span></a><center>Checkpoint</center></h2>

<p> We have thus far made progress with LU and QR factorizations, as well as optimized matrix multiply 
    (which was one of the "nice to haves"). To begin with, a simple sequential algorithm was implemented
    to compute the LU factorization. We then implemented a naive CUDA version of the same and began optimizing
    it. The performance of the LU factorization depends heavily on the memory access patterns and two different
    approaches to accessing memory were tried out. The matrix was divided into blocks and row-wise and column-wise
    accesses within each block were tried out. Another optimization was to use shared memory within each block to
    store the data which is accesses by all threads within the block.</p>
    

<p> We faced some problems initially implementing the blocked version in CUDA, mainly related to array indexing 
    and memory accesses.  We also set up benchmarks to compare our routines to. The in-built
    CUBLAS (CUDA Basic Linear Algebra Subroutines) library is used as a reference. However, the shared memory version
    of LU factorization still has some bugs and fails for higher block sizes, an issue which we are still working on.
    For this reason, timing the LU routine was deferred. </p>
    
<p> The implementation of the QR factorization routine was started simultaneously, which is characterized not by 
    access patterns but by matrix-matrix and matrix-vector multiplications. Again, a sequential version was first implemeneted and then
    a naive CUDA one. With the naive CUDA version, our implementation is 2-3 times worse than the CUBLAS reference
    library for higher matrix dimensions.</p>  
    
  <center><table align="center" style="width:100%">
  <tr>
    <th>Matrix Size</th>
    <th>CUBLAS Time</th>
    <th>Our Time</th>
  </tr>
  <tr>
    <td>4096 x 1024</td>
    <td>47.88s</td>
    <td>155.41s</td>		
  </tr>
  <tr>
    <td>4096 x 2048</td>
    <td>174.01s</td>
    <td>340.02s</td>		
  </tr>
  </table></center>
  
  <p><center>Preliminary results</center></p>
    
<p> Because of the fact that QR Factorization has many matrix-matrix multiplications, it makes sense for us to
    focus on one of our "nice to haves" - the matrix multiplication routine - and optimize it at this stage. One
    of the optimizations which we think will improve our run time performance of the QR routine is to modify the
    algorithm slightly so that the memory allocations are optimal. Another major one would be to use optimized 
    matrix multiply routine instead of the naive one which we have currently written.</p>
    
<p> Finally, we believe that we would be able to produce a library with at least 3 fast and efficient matrix 
    routines - LU factorization, Matrix Multiply and QR factorization. If all goes as planned, we think that the
    other "nice to have" - Cholesky decomposition - is also within reach for us, before the deadline. For the
    Parallelism Competition, we will display a comparison of our implementation with respect to the CUBLAS library
    in the form of a graph.</p>
    
<br>
<br>
<h1 style="color:Aqua">
<a id="Proposal" class="anchor" href="#Proposal" aria-hidden="true"><span class="octicon octicon-link"></span></a><center>Proposal</center></h2>

<h2 style="color:white">
<a id="Summary" class="anchor" href="#Summary" aria-hidden="true"><span class="octicon octicon-link"></span></a>Summary</h2>

<p> We will be developing a library of GPU-accelerated optimized matrix factorization routines in CUDA.</p>


<h2 style="color:white">
<a id="Background" class="anchor" href="#Background" aria-hidden="true"><span class="octicon octicon-link"></span></a>Background</h2>

<p> The factorization routines focused on in this project are LU and QR (and, if time permits, Cholesky)
    Factorization. Both these function involve splitting a given matrix into a product of two matrices. </p>

<h4 style="color:white">
<a id="LU Factorization" class="anchor" href="#LU" aria-hidden="true"><span class="octicon octicon-link"></span></a>LU Factorization</h4>

<p> LU Factorization involves splitting a regular NxN matrix A into a product of a lower triangular matrix L
    and an upper triangular matrix U using Gaussian elimination. This factorization finds applications
    in simplifying linear algebra operations such solving a system of linear equations Ax = b, calculating
    the determinant of a matrix, inverting a matrix etc. </p>
    
<p> A sequential "right-looking" algorithm loops over columns and updates columns to its right based on
    the current column. The following pseudo-code describes the algorithm: </p>
    
 <code>
 <pre> <font color="black">
    for i=1 to N  /*loop over columns*/
      for j= i+1 to N
        A(j,i) = A(j,i)/A(i,i)  /*update L*/
        for k=i+1 to N  
          A(j,k) = A(j,k) - A(i,k)*A(j,i)  /*update U*/
        end
      end
    end  
  </font> </pre>  
 </code>    
 
<h4 style="color:white">
<a id="QR Factorization" class="anchor" href="#LU" aria-hidden="true"><span class="octicon octicon-link"></span></a>QR Factorization</h4>
 
 <p>
   QR factorization splits a rectangular MxN matrix A into two matrices Q and R such that A=QR. Here, Q is a 
   MxM orthogonal matrix whereas R is a NxN upper triangular matrix. This decomposition too is very useful in finding
   solutions to a system of linear equations. QR decomposition is also widely used to solve the linear as well as
   the nonlinear least squares problem.
 </p>
 
 <p>
   The algorithm to decompose a matrix into QR factors is based on the so called Givens rotations which are
   orthogonal. Using a sequence of givens rotations the given matrix can be transformed to an upper 
   triangular matrix. Givens rotations can be systematically applied to successive pairs of rows of matrix A
   to zero entire strict lower triangle. Parallelizing the computation of Givens rotations is one avenue but 
   there could also exist an opportunity to parallelize the step of applying this transformation to pairs of rows.
 </p>
<!-- <img src="images/test_image.jpg" alt="W3Schools.com" width="104" height="142"> -->

<h2 style="color:white">
<a id="Challenge" class="anchor" href="#Challenge" aria-hidden="true"><span class="octicon octicon-link"></span></a>Challenge</h2>

<h4 style="color:white">
<a id="LU Factorization" class="anchor" href="#LU" aria-hidden="true"><span class="octicon octicon-link"></span></a>LU Factorization</h4>

<p>
  The sequential algorithm for the LU decomposition will have to be modified in order to efficiently parallelize 
  it. The data dependencies in the algorithm in outermost loop will have to be dealt with. The algorithm in its
  current form, does not have independent outer loop iterations. Also, the 3 different loops within a matrix imply
  that there are different access patterns possible and an efficient implementation will use one which best exploits locality.
  The challenging part would be to implement a parallel version of the algorithm which best takes advantage of the
  locality in the problem and efficiently uses GPU resources such as shared memory. Thus, the problem should be an
  interesting opportunity to apply platform-specific and application-specific optimizations.
</p>

<h4 style="color:white">
<a id="QR Factorization" class="anchor" href="#LU" aria-hidden="true"><span class="octicon octicon-link"></span></a>QR Factorization</h4>

<p>
  The challenge in this routine is to come up with an algorithm which reduces the amount of synchronization needed. 
  The idea is to exploit parallelism in as many steps of the algorithm as we can by efficiently implementing it on
  a GPU.
</p>

<h2 style="color:white">
<a id="Resources" class="anchor" href="#Resources" aria-hidden="true"><span class="octicon octicon-link"></span></a>Resources</h2>

<p>We will be using a GPU on one of the GHC machines. The references for the LU and QR Factorization are cited
   as [1] and [2] respectively.</p>

<h2 style="color:white">
<a id="Goals and Deliverables" class="anchor" href="#Goals-and-Deliverables" aria-hidden="true"><span class="octicon octicon-link"></span></a>Goals and Deliverables</h2>

<p>The goal of the project is to develop a fast library in CUDA to implement atleast two matrix factorization
   routines.</p>
<p>   
   We expect to deliver an efficient, highly optimized implementation of the two routines on an NVIDIA GPU.
   Moreover, if time permits, we would also extend our project to include a similar efficient implementation of 
   Cholesky Factorization. Matrix multiplication is another application we would like to implement as a part of the
   library. Though not a decomposition routine, we believe it would be a good challenge to implement a optimized 
   matrix multiplication routine as near in performance as possible to state-of-the-art implementations. The 
   performance of the library will be measured by plotting speedup graphs and comparing them with state-of-the-art
   libraries. Another extension is to provide a R interface to these optimized CUDA routines, which was the original
   inspiration behind the project - making R code faster by GPU acceleration.
</p>

<h2 style="color:white">
<a id="Platform Choice" class="anchor" href="#Platform-Choice" aria-hidden="true"><span class="octicon octicon-link"></span></a>Platform Choice</h2>

<p>GPUs are suitable for matrix operations since they offer a huge amount of data parallelism.</p>

<h2 style="color:white">
<a id="Schedule" class="anchor" href="#Schedule" aria-hidden="true"><span class="octicon octicon-link"></span></a>Original Schedule</h2>

<table style="width:100%">
  <tr>
    <th>Day</th>
    <th>Planned Work</th>		
  </tr>
  <tr>
    <td>April 6</td>
    <td>Finalize proposal, Research efficient implementations </td>		
  </tr>
  <tr>
    <td>April 13</td>
    <td>Optimized LU Factorization routine</td>		
  </tr>
  <tr>
    <td>April 20</td>
    <td>Basic QR Factorization routine </td>		
  </tr>
  <tr>
    <td>April 27</td>
    <td>Optimize QR Factorization </td>		
  </tr>
  <tr>
    <td>May 4</td>
    <td>Cholesky/Matrix Multiply </td>		
  </tr>
  <tr>
    <td>May 11</td>
    <td>Finish final report and prepare presentation </td>		
  </tr>
</table>

<h2 style="color:white">
<a id="Schedule" class="anchor" href="#Schedule" aria-hidden="true"><span class="octicon octicon-link"></span></a>New Schedule</h2>

<table style="width:100%">
  <tr>
    <th>Day</th>
    <th>Planned Work</th>		
  </tr>
  <tr>
    <td>April 6</td>
    <td>Finalize proposal, Research efficient implementations, Sequential LU </td>		
  </tr>
  <tr>
    <td>April 13</td>
    <td>3 approaches for LU Factorization, some bugs with shared memory</td>		
  </tr>
  <tr>
    <td>April 20</td>
    <td>Sequential QR Factorization routine and naive CUDA implementation</td>		
  </tr>
  <tr>
    <td>April 24</td>
    <td>Optimize Matrix Multiply, Fix shared memory LU (Ravi) </td>		
  </tr>
  <tr>
    <td>April 27</td>
    <td>QR Factorization - optimal allocations (Harsha) </td>		
  </tr>
  <tr>
    <td>May 1</td>
    <td>Optimize QR - shared memory </td>		
  </tr>
  <tr>
    <td>May 4</td>
    <td>Benchmark results and Cholesky decomposition </td>		
  </tr>
  <tr>
    <td>May 7</td>
    <td>Optimize Cholesky and finish any pending work </td>		
  </tr>
  <tr>
    <td>May 11</td>
    <td>Finish final report and prepare presentation </td>		
  </tr>
</table>

<h3>
<a id="References" class="anchor" href="#References" aria-hidden="true"><span class="octicon octicon-link"></span></a>References</h3>

 <ol type="1">
  <li> Bandara, H. M. D. M., and D. N. Ranasinghe. "Effective GPU Strategies for LU Decomposition". Technical report, University of Colombo, Colombo, Sri Lanka, 2010.</li>
  <li>Kerr, Andrew, Dan Campbell, and Mark Richards. "QR decomposition on GPUs." Proceedings of 2nd Workshop on General Purpose Processing on Graphics Processing Units. ACM, 2009.</li>
</ol> 



